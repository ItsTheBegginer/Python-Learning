# -*- coding: utf-8 -*-
"""CustomerAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19nSaclS2BLgCjk_yanYFnimWRzUq-kdo
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("imakash3011/customer-personality-analysis")

print("Path to dataset files:", path)

import numpy as np
import pandas as pd
import os

csv_file_name = 'marketing_campaign.csv'
csv_file_path = os.path.join(path, csv_file_name)

df = pd.read_csv(csv_file_path, sep='\t')

df.head(10)

df["Income"].isnull().sum()

df["Income"].fillna(df["Income"].mean(), inplace=True)
df["Age"] = (df["Year_Birth"] - 2026)
df["Age"] = df["Age"].astype(int)

print(df["Marital_Status"].head())
print(df["Marital_Status"].unique())

df['Marital_Status'].value_counts()

df['Marital_Status'] = df['Marital_Status'].replace("Married","Together")
df = df[~df["Marital_Status"].isin(["Absurd", "YOLO"])]

print(df['Marital_Status'].unique())

df["TotalSpending"] = df["MntWines"] + df["MntFruits"] + df["MntMeatProducts"] + df["MntFishProducts"] + df["MntSweetProducts"] + df["MntGoldProds"]

import numpy as np
import pandas as pd
import os

csv_file_name = 'marketing_campaign.csv'
csv_file_path = os.path.join(path, csv_file_name)
df = pd.read_csv(csv_file_path, sep='\t')

df["Income"].fillna(df["Income"].mean())
df["Age"] = (2026 - df["Year_Birth"]) # Corrected calculation for Age
df["Age"] = df["Age"].astype(int)

df['Marital_Status'] = df['Marital_Status'].replace("Married","Together")
df = df[~df["Marital_Status"].isin(["Absurd", "YOLO"])]

df["TotalSpending"] = df["MntWines"] + df["MntFruits"] + df["MntMeatProducts"] + df["MntFishProducts"] + df["MntSweetProducts"] + df["MntGoldProds"]

df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], format='%d-%m-%Y')
latest_enrollment_date = df['Dt_Customer'].max()
df['DaysSinceEnrollment'] = (latest_enrollment_date - df['Dt_Customer']).dt.days

columns_to_drop = ['ID', 'Dt_Customer', 'Z_CostContact', 'Z_Revenue']

# Filter out columns that are not present in df to avoid KeyError
existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]
df.drop(columns=existing_columns_to_drop, inplace=True)

# Identify numerical columns for clustering
numerical_cols = df.select_dtypes(include=['number']).columns.tolist()

# Exclude 'Year_Birth' as 'Age' is already derived from it.
if 'Year_Birth' in numerical_cols:
    numerical_cols.remove('Year_Birth')

df_features = df[numerical_cols].copy()

from sklearn.preprocessing import StandardScaler

# Instantiate StandardScaler
scaler = StandardScaler()

# Apply fit_transform to standardize the data
scaled_features = scaler.fit_transform(df_features)

# Convert the scaled features back to a DataFrame
df_scaled = pd.DataFrame(scaled_features, columns=df_features.columns)

print("First 5 rows of the scaled DataFrame (df_scaled):")
print(df_scaled.head())

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

inertia_values = []
k_range = range(1, 11)

for k in k_range:
    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10) # Set n_init explicitly to suppress warning
    kmeans.fit(df_scaled)
    inertia_values.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(k_range, inertia_values, marker='o')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

kmeans_final = KMeans(n_clusters=3, init='k-means++', random_state=42, n_init=10)
kmeans_final.fit(df_scaled)

df['Cluster'] = kmeans_final.labels_

cluster_means = df.groupby('Cluster').mean(numeric_only=True)

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

# Apply PCA to reduce dimensionality to 2 components
pca = PCA(n_components=2)
pca_features = pca.fit_transform(df_scaled)

# Create a DataFrame for PCA results with cluster labels
df_pca = pd.DataFrame(data=pca_features, columns=['PC1', 'PC2'])
df_pca['Cluster'] = df['Cluster'].values

# Plot the clusters
plt.figure(figsize=(10, 8))
sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=df_pca, palette='viridis', s=100, alpha=0.8)
plt.title('Customer Clusters (PCA-reduced)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(title='Cluster')
plt.grid(True)
plt.show()